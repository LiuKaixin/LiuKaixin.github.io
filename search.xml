<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《Top-k Exploration of Query Candidates for Efficient Keyword Search on GraphShaped RDF Data》——读书笔记]]></title>
    <url>%2F2017%2F09%2F29%2F%E3%80%8ATop-k-Exploration-of-Query-Candidates-for-Efficient-Keyword-Search-on-Graph-Shaped-RDF-Data%E3%80%8B%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[首先，初步确定一下本周的规划，今明两天读本篇论文，以及回顾之前的论文（按照师兄说的方式进行泛读），然后周三周四学习斯坦福的课程。周五将没有整理的论文整理完全，周六日搞定本篇和上篇论文。 Abstract从关键词中计算出queries之后，让用户选择合适的，然后送入数据库引擎进行查询。另外对于queries的计算，提出了找top-k子图的新型算法。 1. Introduction提出关键词这样的搜索一直以来都是研究的重点。Labelled query model：不需要用户对结构有任何的了解，只是单纯的将关键词和“labels”联系起来。现在关键词搜索的主要思路：将关键词映射到data elements（很多使用精确匹配），搜索连接关键词的elements的子图（如Blinks中的distinct root assumption），基于得分函数（被提出了很多，从路径长度到IR中的复杂度量）输出top-k个子图（需要计算每个选项的上限和下限）。任务可分为四个： keyword mapping. graph exploration. scoring. top-k computation.本方法结合了语法和语义相似度，因此IR概念支持模糊匹配。本文贡献如下： Keyword Search through Query Computation 将关键词转化为结构化查询的元素（而不是答案的一部分），让用户选top-k个查询中的一个（而不是直接把top-k个答案给出）。 Algorithms for Subgraph Exploration 当前的方法通常将关键词映射到节点，算法计算出树形的答案。但关键词也可能映射到边，所以答案结构也不一定是树。 Efficient and Complete Top-k through Graph Summarization 很难簿记计算top-k所需的信息，现在的方法不能确保结果是真正的top-k。因此我们引入了复杂的数据结构保存所有候选的得分。为了效率，利用摘要图进行剪枝。2. Problem DefinitionData Queries用户的查询$Q_U$就是关键词集合，系统的查询$Q_S$是conjunctive queries. Answers就是把查询中的distinguished variables 替换成子图中的节点。 Problem主要考虑conjunctive queries的计算。3. Overview of the Approach首先举例几个关键词，指出他们之间的连接需要推断关键词之间的连接。以往的工作使用图的schema来推断。本文的方法如下：Query Computation keyword通过映射得到keyword elements。 通过图的搜索将keyword elements连接起来找到connecting element。 connecting element与keyword elements之间的路径构成了matching subgraph。 对于每个子图，通过graph elements到query elements的映射得到conjunctive query。Preprocessing预处理得到keyword index，用于keyword-to-element映射。为了图搜索，建立graph index——原始图的摘要。the augmented index 可以推导query中谓词、常量和结构。Running Example 4. Indexing Graph DataA. The Keyword Index关键词可能指C-vertices，E-vertices，V-vertices或 edges，但在构建索引时忽略E-vertices因为用户不太可能直接输入E-vertex的URI。keyword index 就是一个keyword-element映射，但是对于V-vertex和A-edge所存储的结构比较特殊。为了识别不予数据元素的标签严格匹配的关键词，keyword-element 实现为一个倒排列表。首先对labels进行分析得到其terms，然后利用WordNet得到terms的同义词，上位词和下位词。所以语义相似的graph element会被检出，并用Levenshtein距离度量keywords到terms的语法相似性。 B. The Graph Schema Index用作搜索连接keyword elements的子结构。之前的文章在全图进行搜索，本文旨在从边推出查询结构，从点推出常量（变量）。A-edges和V-vertices并不会有助于连接keyword elements，除非他们就是keyword elements。 构建$G^{‘}_K$需要利用来自映射的数据结构，即[V-vertex, A-edge, $(C-vertex_1,…,C-vertex_n)$]和(A-edge, C-vertex)。为了关键词能够匹配V-vertex，将A-edge$(C-vertex_i,V-vertex)$加入$G^{‘}$;为了关键词能够匹配A-edge，将A-edge$(C-vertex_i,Value)$加入$G^{‘}$. 5. Scoring介绍了一些得分函数，如PageRank（为节点打分），最短路径（为路径打分），TF/IDF（为keyword element打分）。对于图来说，其由路径构成，其成本函数如下： C_G=\sum_{p_i\in P}C_{p_i}而路径由其elements组成： C_{p_i}=\sum_{n\in p_i}c(n)Path Length 假设用户所需的实体紧密相连。其得分函数为$C1=\sum{pi\in P}\sum{n\in pi}1$Popularity Score 计算摘要图中element的popularity，越流行则在路径中贡献越小。$C_2=\sum{pi\in P}\sum{n\in pi}c(n)$，其中对于点v，$c(v)=1-\frac{|v{agg}|}{|V|}$，对于边e，$c(e)=1-\frac{|e{agg}|}{|E|}$。|V|：摘要图中点的总数。$v{agg}$：graph index 中聚集在一个C-vertex的E-vertex的数量。|E|：摘要图中边的总数。$e{agg}$：摘要途中聚集在一个R-edge的R-edge的数量。Keyword Matching Score$C_2=\sum{pi\in P}\sum{n\in p_i}\frac{c(n)}{S_m(n)}$$S_m(n)$代表element n的得分，对于Keyword element，范围是[0,1]，其他元素则一律设置为1。其从语法语义两方面考虑，得分越高则路径的成本越小。 前两个可以离线计算，因为element在不同路径的话，会计算多次，所以其更倾向于Keyword elements紧密连接的子图。 6. Computation of Queries对于查询计算，有五个任务： mapping of keywords to data elements. augmentation of the summary graph. exploration of the graph to find subgraphs connecting the keyword elements. top-k processing. generation of the query for the top-k subgraphs前两个已经解决，本节解决3-5.A. Algorithms for Graph Exploration首先定义最小匹配子图： 一个条件定义包含所有关键词，另一个确保联通。与现有的搜索算法进行对比。Backward Search 从Keyword elements出发迭代地沿入边访问elements直到找到一个connecting element，即answer root。Bidirectional Search 该方法认为从一些顶点可以通过跟随传出而不是传入边缘来更快地达到答案根。故使用启发式激活因子来估计边缘将到达answer root的可能性。这些因子是从一般图形拓扑和已经探索的元素得出的。虽然其在很多情况下表现很好，但最差性能无法保证。Searching with Distance Information 通过存储在索引中的附加连接信息保证最差性能是m-optimal。在每次迭代中，通过该信息可确定能够达到keyword element的elements以及最短的距离，从而有目标的进行搜索。不过构建这些信息十分费力。 因为关键词也有可能对应边，所以查询出的结果不再是树，而是图。成本来自于两方面：query-independent，query-specific。索引技术只能解决query-independent的成本。 B. Search for Minimal Matching Subgraph Input and Data Structures$G^{‘}K$：摘要图$K=(K_1,…,K_m)$：keyword elementsk：查询数量c(n,k,p,d,w): n 刚访问的graph element，k c所在路径起点的keyword element，p 父游标，d 距离，w 成本。$LG^{‘}$: 保存候选子图的全局变量。$K{lowC}$： 存储成本最低的keyword element。 Initialization and General Idea 从一系列keyword elements出发，为每个查询创建游标，游标的拓展就是搜索的拓展。Garph Exploration需要注意邻居可能是出边，入边和点。Computation of Distinct Paths解决环形的问题。Termination 一项被满足 已经计算出所有可能的不同路径，使得LQ中没有更多的游标。 所有keyword elements在给定长度内的所有路径被搜索。 top-k查询被计算。C. Top-k Computation 基本思想来自TA（Threshold Algorithm）算法。候选子图的最高成本——下限的计算，其余子图的最低成本——上限的计算如下：Candidate Subgraphs element n如果能达到所有关键词（其每个关键词游标都不空），则可能对应多个子图（每个游标可能有多个路径），计算每个子图的成本并排序。Remaining Subgraphs 和其他方法相比，我们首先支持图，不限于树。不止是距离信息，还设置了多样的成本函数。首先对这些信息（那些信息）进行索引可以提高Top-k处理和图搜索的效率。In our approach, minimality can be guaranteed for any score metrics, given that the scoring function is monotonic.和【1】对比。时间复杂度$|G|^{d_max}$空间复杂度$k\dot |K|\dot |G|$ D. Query Mapping将子图映射到conjunctive query。Processing of Vertices constant(v) 返回点v的label，var(v)返回v代表的变量。Mapping of A-edgesMapping of R-edges认为相同根的不同答案树是有价值的。将所有答案呈现给用户， 让用户选择。 7. Evaluation基于关键词查询，计算出top-k个conjunctive queries，转化成自然语言问题，并展现给用户。数据集：DBLP、TAP、LUBM。 A. Effectiveness Study12人DBLP—30查询 TAP—9查询使用Reciprocal Rank（RR） =1/r。r是正确查询的排名。 B. Performance Evaluation对比算法：bidirectional search，1000 BFS，1000 METIS， 300 BFS，300METIS。Comparative Analysis query computation的时间，query processing的时间。实验中总时间=计算top-10的时间+处理查询直到找到至少10个答案的时间。Search Performance k 的影响——线性。查询长度Index Performance 索引大小及建索引的时间，都可以接受。 8. Related Worknative approaches：直接在图结构数据上进行关键词搜索，虽然schema-agnostic，但是需要特定的目录和存储机制。Database extensions：可以利用底层数据库的机制，如DBXplorer，Discover。用schema中的信息连接构建的表达式，从而将关键词转成候选网络，再将候选网络转成SQL查询。本方法结合两种方法的优点，一、schema agnostic，构建了schema，并在schema上进行搜索。二、可以利用底层RDF存储的机制。之前工作：计算得出答案，将关键词映射到三元组。本方法：计算得出top-k查询，将关键词映射到查询的element（这样可以支持更多pattern）。前向和后向搜索会利用索引存储关键词信息和路径信息，本方法虽然也用关键词和距离索引，但只是为了计算分数。之前方法计算distinct trees，本方法计算一般子图，因此需要遍历所有的入边和出边。本方法通过预留的索引信息在guided exploration下可以得到最佳的得分，离线部分用索引计算，在线部分用TA计算。但其他方法并不能为结果提供top-k保证。 9. Conclusion and Future Work]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>RDF</tag>
        <tag>Keyword</tag>
        <tag>2017年9月</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客编写]]></title>
    <url>%2F2017%2F09%2F27%2Fhexo%E7%BC%96%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[需参考网站：https://github.com/zhaoqingqing/zhaoqingqing.github.io 昨儿晚上和今天下午都在搞我的博客，本来想搞多终端同步，结果莫名其妙的hexo-admin的deploy功能不能使用了，然后重装了好几次，都没有成功，心里很烦躁。现在冷静下来之后决定用命令去deploy，然后得空去学习js，看看这些东西怎么操作吧。 博客的编写发布主要参考 https://righere.github.io/2016/10/10/install-hexo/首先把hexo分支git clone到本地，然后npm install安装hexo。编辑blog还是用hexo-admin然后使用git add . git commit -m “改了啥”， git push origin hexo将本地仓库同步到远程发布使用命令hexo d -g。 其他终端先pull，之后进行接下来的操作。心好累，弄了半天还是没有什么结果。先暂且这么用着吧。]]></content>
      <categories>
        <category>关于博客</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《Answering top-K query combined keywords and structural queries on RDF graphs》——读书笔记]]></title>
    <url>%2F2017%2F09%2F04%2F%E3%80%8AAnswering-top-K-query-combined-keywords-and-structural-queries-on-RDF-graphs%E3%80%8B%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ABSTRACT虽然SPARQL是RDF图上优越的查询语言，但一些查询意图仍无法使用SPARQL句法表达。关键词搜索虽然能够直观表示信息的需求，但表达准确度较低。为了综合两者的优点，提出了混合查询SK query，并使用基于结构化索引的新型查询算法加速查询。为了更进一步提高SK查询的效率还使用了基于距离的优化技术。 1. Introduction目前RDF图十分流行，图1是Yago知识图谱的一个例子。SPARQL基于子图匹配，是查询RDF数据的标准方法。但是由于用户不了解RDF的schema，所以查询的实体和谓词并不能和数据库中対映。关键词查询是说明信息需求更直观的方法，但也常得到一些无意义的答案。因此本文结合两者的优点提出SK query，其结果是最接近所有关键词的k个SPARQL结果。我们假设关系的强度依赖于路径长度，另外不同的谓词也应该有不同的权重。该问题的另一个挑战是搜索效率，穷举法的流程如下： 用现有技术找出所有匹配的子图。 计算匹配子图和包含关键词的点间的最短路径。 找到路径最短的作为答案。 但该方法太低效，我们为SPARQL查询Q设计了一个下限以尽早结束搜索，另外为结构化剪枝提出一个星型索引。提出一个基于距离的优化加速最短路径距离的计算——选择一些中心点，并使最短路径树以这些点为根；如果搜索到了中心点p，则可以使用根在p的最短路径减少搜索空间。本文贡献： 提出一个新的查询模式——SK query，结合了SPARQL和关键词，并提供了解决方法。 提出星型索引并实现最短路径树（基于距离的优化）以减少搜索空间和提高查询性能。 实验。 2. Background2.1 Preliminaries Definition 2.1. An RDF data graph G is denoted as &lt; V(G), E(G), L&gt;, where (1) $V(G)= V_L \cup V_E \cup V_C$ is the set of vertices in RDF graph G ($V_L,\, V_E,\, V_C$ denote literal, entity and class vertices); (2) E(G) is the set of edges in G; and (3) L is a finite set of edge labels, i.e. predicates.Definition 2.2. An SK query is a pair &lt; Q,q&gt;, where Q is a SPARQL query graph, and q is a set of keywords ${w_1,w_2,…,w_n}$. 对于SK query &lt; Q,q&gt;，查询结果是$&lt; M,{ v_1,v_2,…,v_n} >$, 其中M是Q的子图匹配，$v_i$是包含关键词$w_i$的literal vertex。 Definition 2.3. Given a result $r=&lt; M,{v_1,v_2,…,v_n}&gt;$, the cost of r is defined as follows: Cost(r) =Cost_{content}(r)+Cost_{structure}(r).Definition 2.4. Given a result $r=&lt; M,{v1,v_2,…,v_n}&gt;$, the content cost of r is defined as follows:$Cost{content}(r)=\sum^{i=n}_{i=1}C(v_i,w_i)$,where $C(v_i,w_i)$ is the matching cost between $v_i$ and keyword $w_i$. 结构成本只考虑SPARQL查询中的变量——理由: 用户更感兴趣。（我感觉这并不科研） Definition 2.5. Given a result $r=&lt; M,{v1,v_2,…,v_n}&gt;$, the distance between match M and vertex $v_i$ is defined as follows:$d(M,v_i)=MIN{v\in M}{d(v,vi)}$其中v是M中和SPARQL查询中某个变量相关的点$d(v,v_i)$是v和G中$v_i$的最短距离。结果r的结构成本：$Cost{content}(r)=\sum^{i=n}_{i=1}C(v_i,w_i)$ (Problem Definition) Given an SK query &lt;Q,q&gt; and parameter k, our problem is to find the k results that have the k-smallest costs. 2.2 Predicate salience本文使用最短路径距离评估关系强度。一般的最短路径距离不区分谓词，把”type”、”label”等和普通谓词同等看待不合理。因此引入了predicate salience： ps(p)=\frac{|V(p)|}{|V(G)|} 3. Overview Keyword Mapping. 离线时，为每个关键词建立倒排列表。在线时，根据倒排列表获取关键词对应的节点。对于关键词节点，在给定查询上的常用度量是TF/IDF成本。参考文献中有很多成本函数，我们选择其中一种计算包含关键字的节点的成本。本文中主要关心如何找到SPARQL的匹配以及和关键词之间的关系。我们使用现有的IR引擎分析给定的关键词，并执行不精确匹配得到一些语法或语义相似的元素。Candidate Generation. 如果找到能到达所有关键词的节点，则需要使用子图同态检查SPARQL的子图匹配是否包含该点。此步采用“filter-and-refine”策略，首先找到一些没有在任何Q的子图匹配中出现的dummy节点，如果搜索到dummy节点则不执行子图同态。本文提出一种frequent star pattern-based structural index。基于该索引可以为SPARQL查询的变量提供候选列表。Top-k Results Computation. 基于图搜索，循环地计算关键词节点与邻居的距离，找到一个能达到所有关键词的节点，如果不是dummy vertex，则使用SPARQL matching算法。 4. Candidate generation based on the structural index4.1 Structural index本节提出一个frequent star pattern-based index。从G中挖掘出一些常见的星型模式，并为每个星型模式建立一个节点的倒排列表。选择星型的原因是在SPARQL查询常包含星型子查询。星型模式的挖掘使用现有的sequential pattern挖掘算法，如PrefixSpan。我们不能为每个星型模式建立目录，因此我们我们定义了discriminative ratio。 Definition 4.1. Given a star S, its discriminative ratio is defined as follows:$\gamma (S)=\frac{|L(S)|}{|\cap_{S^{‘}\subset S} \,\,L(S^{‘})|}$ 如果$\gamma (S)$越大，则说明如果保存S的子集作为目录元素的话，就没必要保存S作为目录元素。因此设定$\gamma (S)\le \gamma_{max}$。但对于只有一条边的星型查询，我们始终将其放入目录中。 Theorem 4.1. Let F denote all selected index elements (i.e., frequent star patterns). Given a SPARQL query Q, a vertex v in graph G can be pruned (there exists no subgraph match of Q containing v) if the following equation holds.$v\notin \cup_{S\in F \land S \in Q}L(S)$,]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>2017年9月</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Keyword Search in Graphs: Finding r-cliques》——读书笔记]]></title>
    <url>%2F2017%2F08%2F24%2F%E3%80%8AKeyword-Search-in-Graphs-Finding-r-cliques%E3%80%8B%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ABSTRCT图上的关键词搜索是找到一个包含所有关键词的子结构，之前的工作都是找最小连通图（connected minimal trees），而现在发现找子图比找子树对用户来说更有用。子树中的关键词节点（content nodes）彼此间可能并不紧连，另外，在找子树时会遍历整个图而不仅是关键词节点。An r-clique is a group of content nodes that cover all the input keywords and the distance between each two nodes is less than or equal to r. 1. INTRODUCTION keyword search in databases.是联通子树（这是一本书，我没看。。。）。李国良的文章Ease: Efficient and adaptive keyword search on unstructured, semi-structured and structured data 的答案是半径不大于r的斯坦纳树。 以前基于树或图的方法存在的问题： 一些关键词节点（content nodes）相距太远。 对所有的节点遍历，时间和空间复杂度都很高。 使用r-cliques的优点： 所有关键词节点相距很近。 无需遍历所有节点。 举例说明：关键词：James, John, Jack。 r=10。图2(a)中的答案比图2(c)中的更加合理，因为三个点在同一个组织。另外三边之和也是图2(a)更小。但是对于用文献13生成的两者的斯坦纳树，结果相反。 本文贡献： 提出一个新的图关键词搜索的模型。 证明找到有最小权重的r-clique是NP-hard问题。 基于Branch和Bound的算法找到所有的r-cliques。 提出一个找2个近似度的r-cliques的近似算法，能在多项式时间内以升序找到所有的r-clique。 为了找到某个r-clique中的节点的关系，提出在图中找连接r-clique中节点的斯坦纳树。 Exact Top-k Nearest Keyword Search in Large NetworksThere are other keyword search problems that are of some different characteristics. The general idea of keyword search is to find a subgraph in a given graph that contains the query keywords.The subgraph can be of the form of a tree in some cases. BANKS in [5] converts a relational database into a graph and answers to keyword queries are directed subtrees in the graph. Given a directed graph, the keyword search in [16] returns top ranked subtrees in the graph that cover the query keywords. Blinks [18] also considers directed graph and given a keyword query, an answer is a subtree in the graph that covers the keywords and the root of the subtree can reach all the keywords. Top-k results are top k subtrees with different roots. The graph type of r-clique is introduced in [21] as the form of expected answers. An r-clique is a set of vertices in the given graph which covers the given query keywords and the distance between any pair of the vertices in this set is no longer than r. Both exact and approximate algorithms have been proposed in [21]. Querying the neighbors of a vertex in a compressed social network is considered in [24] Efficient processing of keyword queries over graph databases for finding effective answers一篇较新的关于树形的文章。 the minimal Steiner tree semantics.将答案树的权重定义为边的和，所以问题就转化成optimal group Steiner tree problem.有些人用启发式的规则得到l倍近似的结果（l是关键词数目）；有人用dp…但这些方法并不能有效的在大图上得出top-k Steiner tree-stuctured answers. distinct root semantics.答案树的权重为根节点到关键词节点的最短路径之和，每个根节点只有权重最小的答案树被作为候选。因此，对于n个点的图，至多有n个答案，所以比斯坦纳树更高效（这里没懂）。 之前的工作限制着包含一个关键词的节点个数有且只有一个，本文中答案树包含一个关键词的节点可能有多个。 Survey on Keyword Search over XML Documents 该文第3章提出对于XML关键词搜索基于图的方法。 Subtree based Semantics for Directed Graphs. the minimal Steiner tree semantics. Keyword proximity search in complex data graphs. the distinct root semantics. BLINKS: ranked keyword searches on graphs Subgraph based Semantics for Undirected Graphs. (方法的优劣暂且不论，其应用在无向图，但RDF是有向图) r-radius semantics. EASE: Efficient and adaptive keyword search on unstructured, semi-structured and structured data.（2008） r-clique semantics. Keyword search in graphs: finding r-cliques（2011） minimum cost connected tree. Finding top-k min-cost connected trees in database.（2007） Bi-directed Tree based Semantics for Directed GraphsBANKS和Bidirectional expansion for keyword search on graph databases（2005）返回有前向边或后向边的子树。Finding and approximating top-k answers in keyword proximity search返回混合了前向边和后向边的子树。（2006）]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>Keyword</tag>
        <tag>2017年9月</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Natural Language Question Answering over RDF —— A Graph Data Driven Approach》——论文笔记]]></title>
    <url>%2F2017%2F08%2F24%2F%E3%80%8ANatural-Language-Question-Answering-over-RDF-%E2%80%94%E2%80%94-A-Graph-Data-Driven-Approach%E3%80%8B%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ABSTRACTRDF Q/A允许用户对RDF知识库用自然语言提问。为回答该提问，需要两步：理解问题和执行查询。现有工作大都集中在解决自然语言的歧义，通常做法是the joint disambiguation，使搜索空间指数增长。本文从图数据驱动的角度解决该问题，提出使用语义查询图为自然语言的查询意图建模，将问题归约成子图匹配问题。更重要的是，我们通过查询的匹配情况，解决自然语言问题的多义性。实验结果验证算法。 1. INTRODUCTION背景：用户需从知识库中获取知识，RDF格式成为标准，SPARQL查询对用户不友好，需要RDF Q/A系统。 1.1 Motivation 现在RDF Q/A系统主要分两个阶段：question understanding和query evaluation。第一阶段把自然语言问题N转化成SPARQLs，这也是目前大部分工作的研究重点。第二阶段执行第一阶段得到的SPARQls。如图1所示，(a)是RDF数据集，(b)是目前解决方法的两个步骤，可以看到由于多义性，有些短语对应多个实体。如果同时考虑这些短语则增加了响应时间。本文并不在第一阶段解决多义性问题，而是放到第二阶段，能够避免问题理解阶段的高昂的消歧处理，从而加速整个系统。本方法中最关键的问题在于如何定义RDF图G中的子图和自然语言问题N的匹配，以及如何找到匹配。 1.2 Our Approach虽然本方法仍有“question understanding”和“query evaluation”，但并不与现在的SPARQL generation-and-evaluation相同，本方法是graph data-driven，其大概的框架如图1(c)。在question understanding阶段，我们把问题iN翻译为semantic query graph $Q^{S}$。该步允许多义。在query evaluation阶段，我们在图G上找$Q^{S}$的匹配的子图。我们基于语义相似性定义了匹配的分数。将消歧放在query evaluation阶段不仅提高了精度也加速了整个查询应答时间。贡献： 为问题提出了系统的框架。并从graph data-driven的角度，将消歧放在了query evaluation阶段。 离线处理：提出图挖掘算法，将短语匹配到top-k个可能的谓词，形成paraphrase dictionary D。 在线处理：两个阶段，首先将问题N转换为semantic query graph $Q^{S}$，然后把RDF Q/A归约成$Q^{S}$在图G上的子图匹配问题。在找到匹配时解决了多义问题，如果没有匹配发现则消歧的花费就被节省了。 实验 2. FRAMEWORK 本问题有两个关键的挑战，一是如何以结构化的方式表示问题N中的查询意图。二是如何处理问题N中的短语的多义性。为解决第一个挑战，我们从N中抽出semantic relations，并基于此建立了semantic query graph $Q^{S}$为问题N中的问题意图建模。 Definition 1. (Semantic Relation). A semantic relation is a triple , where rel is a relation phrase in the paraphrase dictionary D, arg1 and arg2 are the two argument phrases.Definition 2. (Semantic Query Graph) A semantic query graph is denoted as $Q^S$, in which each vertex $v_i$ is associated with an argument and each edge $\bar{v_iv_j}$ is associated with a relation phrase, $1\le i,j\le |V(Q^{S})|$. 针对第二个挑战，我们提出了数据驱动的方法：对于N中一个短语到实体的映射，如果能找到包含该实体的子图且匹配N中的查询意图，那该映射是正确的；否则是错误的。 2.1 Offline建立了paraphrase dictionary D——记录语义相等的关系短语和谓词。一些现有的系统如Patty和ReVerb还未每个关系短语提供了其支持的实体对，如表2。方法思路：对每个关系短语$rel_i$，$Sup(rel_i)$表示一系列该谓词支持的实体对。我们假设这些实体对也出现在RDF图中。频繁出现的谓词连接$Sup(rel_i)$中的实体对和关系短语$rel_i$等价。基于该想法我们提出一个找语义相等的关系短语和谓词的图挖掘算法。 2.2 Online1) Question Understanding. 目的在于为问题N构建一个语义查询图$Q^{S}$。首先用Stanford Parser得到N的依赖树Y，然后基于paraphrase dictionary D抽取Y中的语义关系。基本的思路是找到一个Y的包含rel的所有词的最小子树。该子树被称为Y中的rel的一个嵌入，并且基于一些语言规则我们得到有联系的两个参数，形成$&lt; rel,arg1,arg2 &gt;$，最后连接这些关系得到查询图$Q^{S}$。2) Query Evaluation. 找到与$Q^{S}$匹配的子图。匹配按照子图同态定义。 首先，$Q^{S}$的点，被映射到RDF图中的一些实体或类，并赋予一个置信度，保存在有序列表$C{v_i}$。关系短语$rel{\overline{viv_j}}$被映射到候选谓词的列表$C{\overline{v_iv_j}}$中。列表以置信度排序。本步中并没有解决多义问题。其次， Definition 3.(Match) Consider a semantic query graph $Q^{S}$ with n vertices ${v1,…,v_n}$. Each vertex $v_i$ has a condidate list $C{vi},i=1,…,n.$ Each edge $\overline{v_iv_j}$ also has a candidate list of $C{\overline{v_iv_j}}, where $1\le i\ne j\le n.$ A subgraph M containing n vertices ${u_1,…,u_n}$ in RDF graph G is a match of $Q^{S}$ if and only if the following conditions hold: if $vi$ is mapping to an entity $u_i$, i=1,…,n, $u_i$ must be in list $C{v_i}$; if $vi$ is mapping to a class $c_i$, i=1,…,n, $u_i$ is an entity whose type is $c_i$ (i.e., there is a triple &lt;$u_i$ rdf:type $c_i$&gt; in RDF graph) and $c_i$ must be in $C{v_i}$; $\forall \overline{viv_j}\in Q^S; \, \overrightarrow{u_iu_j}\in G \lor \overrightarrow{u_ju_i}\in G$. Furthermore, the predicate $P{ij}$ associated with $\overrightarrow{uiu_j}$ (or $\overrightarrow{u_ju_i}$ is in $C{\overline{v_iv_j}},\, 1\le i,j\le n$. 每个和$Q^S$匹配的子图都有一个得分，由边和点的概率决定。我们的目标是找到top-k个匹配的子图，在4.2.2节中解决。 3. OFFLINE 语义关系抽取依赖于词典D，图3是词典的一个示例。本文并不讨论如何抽取短语及其对应的实体对，假设已经给定。在offline中的任务是找到语义相等的关系短语和RDF中的相应谓词，即构建如图3的词典D。假设已有词典$T={rel1,…,rel_n}$，每个$rel_i$都是一个关系短语，并有一个出现在RDF图中的实体对集合，即$Sup(rel_i)={(v^1_i,V^{‘1}_i),…,(v^m_i,V^{‘m}_i),}$。对于每个$rel_i$目标是找到RDF图中的top-k个语义相等的谓词（路径）。方法：给定一个关系短语$rel_i$及$Sup(rel_i)={(v^1_i,V^{‘1}_i),…,(v^m_i,V^{‘m}_i),}$，对$(v^j_i,V^{‘j}_i),j = 1,…,m$，我们在RDF图中找到两点间的简单路径：$Path(v^j_i,V^{‘j}_i)$，如图4。则$PS(rel_i)=\bigcup{j=1,…,m}Path(v^j_i,V^{‘j}_i)$. 为了效率，我们设定了路径的阈值，然后使用双向的BFS搜索找到$Path(v^j_i,V^{‘j}_i)$。但是这样的方法会带来噪音，解决方法：采用了tf-idf度量。 Definition 4. Given a predicate path L, the tf-value of L in $PS(rel_i)$ is defined as follows: tf(L,PS(rel_i))=|\{Path(v^j_i,V^{'j}_i)| L\in Path(v^j_i,V^{'j}_i)\}|The idf-value of L over the whole relation phrase dictionary $T={rel_1,…,rel_n}$ is defined as follows: idf(L,T)=log \frac{|T|}{|\{rel_i\in T|L \in PS(rel_i)\}|+1}The tf-idf value of L is defined as follows: tf-idf(L,PS(rel_i),T)=tf(L,PS(rel_i))\times idf(L,T) 关系短语和谓词（路径）的置信度定义为： \delta (rel,L)=tf-idf(L,PS(rel_i),T) \tag{1} 算法1展示了为每个关系短语找top-k谓词路径的细节。注意tf-idf is a probability value to evaluate the mapping (from relation phrase to predicate/predicate paths) confidence.维护D只需要为新引入的谓词重新挖掘映射，或删除被移除数据集的谓词的映射。 Theorem 1. The time complexity of Algorithm 1 is $O(|T|\times |V|^2\times d^2)$, where |T| is the number of relation phrases in T, |V| is the number of vertices in RDF graph G, and d is the maximal vertex degree. 4. ONLINE4.1 Question Understanding本节讨论如何识别问题N中的语义关系，并基于关系建立语义查询图$Q^S$代表N中的查询意图。为抽取句子关系短语，建立依赖树。图5展示了问题N的依赖树表示为Y。 Definition 5. Let us consider a dependency tree Y of a natural language question N and a relation phrase rel. We say that rel occurs in Y if and only if there exists a connected subtree y (of Y) satisfying the following conditions: Each node in y contains one word in rel and y includes all words in rel. We cannot find a subtree $y^{‘}$ of Y, where $y^{‘}$ also satisfies the first condition and y is a subtree of $y^{‘}$.In this case, y is an embedding of relation phrase rel in Y. 给定问题N的依赖树Y和关系短语词典$T={rel_1,…,rel_n}$，我们需要T中那个关系短语在Y中出现。 4.1.1 Finding Relation Phrase Embeddings Theorem 2. The time complexity of Algorithm 2 is $O(|Y|^2)$. 4.1.2 Finding Associated Arguments通常参数的识别依赖subject-relations、object-like relations，如下： subject-like relations: sbj, nsubj, nsubjpass, csubj, csubj-pass, xsubj, poss; object-like relations: obj,pobj, dobj, iobj 假设关于短语rel的嵌入子树为y。通过检查y中的每个节点w及其子节点是否出现以上的subject-like（object-like）关系，出现则把子节点加入到arg1（arg2）。如果arg1/arg2仍是空，我们有以下启发式规则： Rule 1: Extend the embedding t with some light words, such as prepositions, auxiliaries. Recognize subject/object-like relations for the newly added tree node. Rule 2: If the root node of t has subject/object-like relations with its parent node in Y, add the root node to arg1. Rule 3: if the parent of the root node of t has subject-like relations with its child, add the child to arg1. Rule 4: If one of arg1/arg2 is empty, add the nearest wh-word (such as what, who and which) or the first noun phrase in t to arg1/arg2. 如果arg1/arg2仍然是空，则放弃关系短语rel。 4.1.3 Building Semantic Query Graph把语义关系表示为边，如果两个关系的参数相同，则边相连。 4.2 Query Evaluation4.2.1 Phrases Mapping讨论如何将关系短语和参数映射到候选的谓词（路径）和实体。Mapping edges of $Q^S$. $Q^S$中边$\overline{viv_j}$对应关系短语$rel{\overline{viv_j}}$。按照paraphrase dictionary D，$rel{\overline{viv_j}}$映射到列表$C{\overline{v_iv_j}}$，列表中是谓词P或谓词路径L。$\delta(rel,L)$置信度。Mapping Vertices of $Q^S$. $Q^S$中点v对应参数arg。如果arg是wh-word，则它可映射到RDF中所有实体和类，否则返回一个对应的实体或类的列表。本文使用现成的工具DBpedia Lookup。$\delta(arg,c)$置信度。Graph Data-driven Disambiguation. graph data-driven solution. 4.2.2 Finding top-k Subgraph Matches Definition 6. Given a semantic query graph $Q^S$ with n vertices ${v_1,…,v_n)}$, a subgraph M containing n vertices ${u_1,…,u_n}$ in RDF graph G is a match of $Q^S$. The match score is defined as follows: Score(M)= log( \prod_{v_i\in V(Q^S)} \delta (arg_i,u_i) \times \prod_{\overline{v_iv_j}\in E(Q^S)} \delta (rel_{\overline{v_iv_j}},P_{ij}) )\\ =\sum_{v_i\in V(Q^S)} log( \delta (arg_i,u_i))+\sum_{\overline{v_iv_j}\in E(Q^S)} log( \delta (rel_{\overline{v_iv_j}},P_{ij}) ) \tag{2}where $argi$ is the argument of vertex $v_i$, and $u_i$ is an entity or a class in RDF graph G, and $rel{\overline{viv_j}}$ is the relation phrase of edge $\overline{v_iv_j}$ and $P{ij}$ is a predicate of edge $\overrightarrow{u_iu_j}$ or $\overrightarrow{u_ju_i}$ 给定语义查询图$Q^S$，我们目标是找到$Q^S$的所有匹配中分数top-k的。这是个NP-hard问题。 Lemma 1. Finding Top-1 subgraph match of $Q^S$ over RDF graph G is an NP-hard problem.Lemma 2. Finding Top-k subgraph match of $Q^S$ over RDF graph G is at least as hard as finding Top-1 subgraph match of $Q^S$ over G.Theorem 3. Finding Top-k subgraph match of $Q^S$ over RDF graph G is an NP-hard problem. 因为他是NP-hard问题，所以我们设计启发式规则减少搜索空间。第一个利用neighborhood-based pruning减少$C{v_i}$和$C{\overline{v_iv_j}}$。第二个是基于top-k匹配的分阈值及早停止搜索。 5. TIME COMPLEXITY ANLYSIS 6. EXPERIMENTS]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>RDF</tag>
        <tag>2017年8月</tag>
        <tag>QA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Scalable Keyword Search on Large RDF Data》——论文笔记]]></title>
    <url>%2F2017%2F08%2F20%2F%E3%80%8AScalable-Keyword-Search-on-Large-RDF-Data%E3%80%8B%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Abstract目前关键词搜索的两种方法：一、依赖建立距离矩阵来剪枝搜索空间，二、为RDF图建立摘要。本文指出现有技术面对真实数据集时的不足，并且提出一个新的摘要算法，能够更有效的剪枝并得到正确的答案。 1 Introduction 动机：RDF数据急速增长。关键词搜索对大规模数据十分有用，目前对于RDF数据的解决方法的局限： 返回不正确的答案。 难以处理大规模RDF数据。 目标：设计一个能处理大规模RDF数据集的scalable and exact soluton。 贡献： identify and address limitations in the existing methods for keyword search in RDF data. 并基于后向搜索提出一个正确的baseline解法。 develop efficient algorithms to summarize the structure of RDF data, based on the types in RDF graohs. 和之前的方法相比more scalable剪枝也更有意义，并且得到的摘要是轻量级的而且可更新。 experiments on both benchmark and large real RDF datasets. 2 Preliminaries将RDF数据集看做RDF图G=(V,E)其中 $V={V_E,V_T,V_W}$ $V_E$: the set of entity vertices. $V_T$: the set of type vertices. $V_W$: the set of keyword vertices. $E={E_R,E_A,E_T}$ $E_R$: the set of entity-entity edges. $E_A$: the set of entity-keyword edges. $E_T$: the set of entity-type edges. 图1中主要结构被entity-entity edge即$E_R$捕获，因此将entity vertex和关于他的type vertex和keyword vertex看做一个点，我们得到RDF图G的压缩视图，表示为$G_c={V^{‘}_E,E_R}$。其中$|V^{‘}_E| \equiv |V_E|$，$v^{‘}\in V^{‘}_E$包含$v\in V_E$和与之联系的类型和关键词节点。 2.1 Problem statement关键词查询问题即RDF图中寻找包含所有关键词的子图。为便于表示，假设每个节点只包含一个关键词。（但对于包含多个和不包含的也能处理）对在$G={V,E}$上的查询$q={w_1,w_2,…,w_m}$，点集${r,v_1,…,v_m}$在以下条件成立时被称为 qualified candidate: root answer node $r\in V$能够到达任一点$v_i\in V,\, i\in [1,m]$ $w(v_i)=w_i$ A(q): the answer for qC(q): the set of all qualified candidates in G with respect to q. A(q)= arg min_{g\in C(q)}s(g), \, and \, s(g)=\sum_{r,v_i\in g, i=1..m}d(r,v_i)\tag{1}其中$d(r,v_i)$是从r到$v_i$的距离（不考虑边方向）。 该定义还有一个top-k版本，其中对每个$g\in C(q)$的得分s(g)进行升序排列，得到前k个答案。 3 Related work许多技术假设图能够在内存中处理，如14 17为所有的点对保存了距离矩阵。另外这些工作不考虑如何处理更新。本文中我们将后向搜索应用于大RDF图并经过严密的证明，不依赖于距离矩阵。关于摘要大图来支持关键词搜索的技术来自于[9]，作者假设块之间的边是有权重的，块被当做supernode，块之间的边被当做superedges，它们组成摘要图。然后循环此过程。该方法针对通用图，并不能拓展到RDF图中。[23]研究了RDF图上的关键词搜索，和本文一样，其调整了[14]中的问题定义。该方法从RDF数据集中摘要出schema，在schema中应用后巷搜索得到最有可能的关系，然后将关系转化为SPARQL中的pattern进行检索。[23]中摘要算法的局限：将同一类型的所有实体归结到一个点，丢失了太多信息，以至于产生错误结果。另外该方法不支持更新。[18]中通过对异质关系编码为图，支持结构化，半结构化和非结构化的关键词查询。同样的，他也需要距离矩阵。11 12研究了排序函数。我们则是调整了RDF[23]和通用图[14]中的排序函数。 4 The Baseline Methodbaseline基于“backward search”的启发式。“backward search”：图中对应关键词查询的所有节点同时开始，迭代地想邻居节点拓展，直到候选答案生成。termination condition用来判断搜索过程是否完成。[23]中的termination condition是当m个节点第一次遇到节点r时返回答案并停止搜索，但该方法并不正确。Counter example. 对于图a来说，第二轮迭代得到$g={r=v_4,v_1,v_2,v_6,v_7}\, \, s(g)=8$，但第四轮迭代中$g^{‘}={r=v_3,v_1,v_2,v_6,v_7}\, \, s(g^{‘})=6$。The correct termination. 如算法1.Data structure. $q={w_1,…w_m}$: query G={V,E}: a (condensed) RDF graph $W_i$: vertices in V containing the keyword $w_i$ ${a_1,…a_m}$: m empty priority queues, one for each query keyword. M: 集合中每个元素对应目前探索到的独一无二的node，记录他们能够到达那个关键词以及距离。对于fig5(a)，$M[v_3]={(v_1,1),(v_2,1),nil,(v_7,1)}$The algorithm. (图片中是不是line10,11写错了？）第一轮迭代算是初始化$a_i$和M。$W_i$中每个v和其邻居u放入$a_i$中，并新建$M[u]$或更新$M[u]$的相应值。第二轮迭代首先pop$a_i$的堆顶值，然后添加 $(v,p={v,…,u},d(p))}$中u的每个邻居$u^{‘}$。将 $(v,p={v,…,u^{‘}},d(p)+1)}$压入$a_i$然后更新$M[u^{‘}]$。如果$M[u]$没有nil，则该条被标记为候选答案，u为候选根节点。将M[u]中的最短路径表示为g，我们有： Lemma 1 $g={r=u,v{l_1},…,v{lm}}$ is a condidate answer with $s(g)=\Sigma^m{i=1}d(u,v_{l_i})$. 两种情况：(i) an unseen vertex, i.e., $v\notin M$, will become the answer root(Lemma 2); (ii) a seen but not fully expanded vertex $v\in M$ will become the answer root(Lemma 3).$V_t$: the set of vertices that are not fully explored.$(v_1,p_1,d(p_1)),…(v_m,p_m,d(p_m))$: the top entries from $a_1…a_m$. Lemma 2 Denote the best possible candidate answer as $g1$, and a vertex $v\notin M$ as the answer root of $g_1$. Then it must have $s(g_1)&gt;\Sigma^m{i=1}d(p_i)$.Lemma 3 Suppose the best possible candidate answer using such an $v(v\in M\, and \, v\in V_t)$ as the answer root is $g_2$ then s(g_2)>\sum^m_{i=1}f(v_{b_i})d_i + (1-f(v_{b_i}))d(p_i) \tag{2}where $f(v{b_i})=1$ if $M[v][b_i]\neq nil$, and $f(v{b_i})=0$ otherwise. The termination condition. 对于情况(i)，我们简单的让$s(g1)=\Sigma ^m{i=1}d(p_i)$;对于情况(ii)，we find a vertex with the smallest possible $s(g_2)$ value w.r.t. the RHS of (2), and simply denote its best possible score as $s(g_2)$.Denote the kth smallest candidate answer identified in the algorithm as g, our search can safely terminate when $s(g)\le min(s(g_1),s(g_2))=s(g_2)$. Theorem 1 The Backward method finds the top-k answers A(q,k) for any top-k keyword query q on RDF graph. 5 Type-Based SummarizationBackward方法对大的RDF图不适用，因为Backward为完成搜索，会构建无数的搜索路径。为了减少Backward算法的输入规模，只在有希望的子图上应用。我们提出了一个type-based摘要方法，即先在摘要图上进行关键词搜索，剪枝掉大部分无用的结果，然后再应用Backward。The intuition. 首先对RDF图分区，被查询的关键词首先由分区连接。挑战在于如何对不会产生top-k跨区答案进行剪枝。要做到这个我们需要对跨越分区的后向搜索的路径距离进行校正。但维护所有路径的距离成本太高，因此我们提取一个可更新的摘要图，使得任何后向搜索可以被有效地估计。The key observation: 紧邻的相同类型邻居节点一般共享相似的结构——和其他类型的节点的连接，如fig6。我们基于以上观察构建一个typed-based summary。 5.1 Outline and preliminaries首先将RDF图划分为多个小的区，然后定义摘要了分区的type-baseed structures。摘要保存所有分区的不同结构。通常关键词搜索在两方面受益于摘要： we can obtain the upper and lower bounds for the distance traversed in any backward expansion without constructing the actual path (Section 6). we can efficiently retrieve every partition from the data by collaboratively using SPARQL query and any RDF store without explicity storing the partition (Section 15). 两个定义：Homomorphism across partitions. 如图6(a)所示，邻近的类型节点是生成induced partitions的好的源头。图6(a)是图6(b)的子集。We consider discovering such embeddings between the induced partitions, so that one template can be reused to bookkeep multiple structures. Definition 1 A graph homomorphism f from a graph $G={V,E}$ to a graph $G^{‘}={V^{‘},E^{‘}}$, writtern as $f: G\rightarrow G^{‘}$, is a mapping function $f: V\rightarrow V^{‘}$ such that(i) f(x)=x indicates that x and f(x) have the same type; (ii) $(u,v)\in E$ implies $(f(u),f(v)) \in E^{‘}$ and they have the same label. When such an f exists, we say G is homomorphic to $G^{‘}$. Cores for indeividual partitions. A core is a graph that is only homomorphic to itself, but not to any one of its proper subgraphs.Definition 2 A core c of a graph G is a graph with the following properties: there exists a homomorphism from c to G; there exists a homomorphism from G to c; and c is minimal with these properties. 5.2 Partition摘要过程开始于将数据分成较小的，语义相似的，边不相交的子图。鉴于我们观察到相同类型的节点共享相似的类型邻居，我们基于类型用环绕相同类型节点的子图对G划分。算法使用RDF的condensed视图。${T_1,…,T_n}$: n distinct number of types.$V_i$vertices whose type is $T_i$.h(v,$\alpha$)(the $\alpha$-neighborhood of v): the subgraph from G obtained by expanding v with $\alpha$ hops. 拓展时的边不在P中，且是有向图，所以h(v,$\alpha$)是v $\alpha$跳邻居节点的子集。P：初始化为空，然后每个h(v,$\alpha$)都是一个新的划分。 Lemma 4 Partitions in P are edge disjoint and the union of all partitions in P cover the entire graph G. 我们遍历类型的顺序不同可能会影响分区P的最终结果。但无论怎样，同种类型的节点总是基于其$\alpha$-neighborhoods生成一系列划分。如图8。 5.3 Summarization摘要算法从P的分区集合中识别出一系列templates。这些templates是partitions 的摘要。另外摘要算法保证P中的每个分区都与某个templates同态。该特性是的查询优化器： 不用频繁访问RDF数据的前提下有效地在后向拓展时估计路径长度。 通过查询RDF数据来有效地重构感兴趣的分区，而不显式地存储和索引分区。 给定一个分区P，算法3检索出所有的不同的结构并将其保存在S中。Improving efficiency and reducing |S|.算法3的两个问题：(1)在3,5,7行需要判断同态，这是NP-hard问题。(2) 尽量减少|S|的大小，以便能够放入内存中处理。对$h(v,\alpha)$的边建立一个covering tree，即$h_t(v,\alpha)$。并用$h_t(v,\alpha)$代替$h(v,\alpha)$。Example 2. 图9中，$h(v_1,2)$$中$v_4$节点在不同边中被访问了三次，所以有三个拷贝。该方法的优点： 降低S中不同结构的数量，如图9所示，两个在数据层面不同的结构，在类型层面共享一个结构。 对于通用图来说，检测子图同态十分耗时。但能在多项式时间内检测类型层面的结构。 5.4 Auxiliary indexing structures为了帮助关键词搜索，我们维护了三个辅助列表。a portal node：node that isincluded in more than one partitions. portal index for each partition $h(v,\alpha)$, 我们赋予其唯一id并和portal列表联系。$\sigma (v_i)$: 表示$h_t(v,\alpha)$中的所有$v_i$。$\Sigma={\sigma (v_1),\sigma(v_2),…}$：表示一个分区中所有的一对多的映射。如图9中，$h(v_1,2)$$\Sigma \leftarrow {\sigma (v_4)={T_4}}$. partition index: to map the partition root v of $h(v,\alpha)$ to its $\Sigma$.summary index: 将partitions中的节点映射到S中的摘要节点。sid: S中的每个摘要的id，nid: S中每个节点的id。为了获得每个$h_t(v,\alpha)$到S中的summary的映射，需要建立日志保存建立S时的发现的所有同态。等S建立完成后我们遍历日志找到所有从数据到summary的映射。过程如图10. 6 Keyword search with summary搜索算法，摘要层和数据层的两级后向搜索。只有摘要层中被识别的connected partitions包含所有关键词，并且其分数在top-k，才会进入数据层执行后向搜索。路径长度计算是后向搜索和剪枝的核心，但摘要层并不能拿到准确的路径长度，因此首先展示如何估计路径长度，然后介绍算法。 6.1 Bound the shortest path length通过summary index，分区根节点v到分区内任一节点u的最短距离可计算，所以由三角形不等式得：$|d(v,v_1)-d(v,v_2)|\le d(v_1)-d(v_2)\le |d(v,v_1)+d(v,v_2)|$。另外，另一个下界可用根节点v所在分区的同态的摘要图得到，即Lemma 5： Lemma 5 Given two graphs g and h, if $f:g\rightarrow h$, then $\forall v_1,v_2\in g$ and their homomorphic mappings $f(v_1),f(v_2)\in h,\, d(v_1,v_2)\le d(f(v_1),f(v_2))$. 如图11，从h到s没有直接的同态，因此不能直接应用Lemma 5。定义映射函数Join。输入：图g，${V^{‘}{t_1},V^{‘}{t2},…}$。输出：新图$g^{‘}=Join(g(V,E),{V^{‘}{t1},V^{‘}{t2},…})$。其中$V^{‘}{t_i}$中的点都属于类型$t_i$。函数流程： 用g初始化$g^{‘}$； 将$g^{‘}$中的$V^{‘}{t_i}$合并至类型为$t_i$的点$v^{‘}{i}$，点集$V^{‘}{t_i}$中的所有边也赋于$v^{‘}{i}$； 对所有类型重复步骤2。 Example 3. 以图9为例，$Join(h_t(v_1,2),{\Sigma(T_4)})$重建了$h(v_1,2)$，因此两者同态。另外，$Join(h_t(v_5,2),{\Sigma(T_4)})$没有重建$h(v_5,2)$，但等于$h(v_1,2)$也和$h(v_5,2)$同态。 Lemma 6 For a partition h and its covering tree $h_t$, there is a homomorphism from h to $Join(h_t,\Sigma)$.Lemma 7 For a partition h, its covering tree $h_t$ and its summary s that has $f_2:h_t\rightarrow s$, there is a homomorphism from $Join(h_t,\Sigma)$ to $Join(s,f_2(|Sigma))$. 如图11b，由Lemmas 6,7和同态的可传递性，h is homomorphic to $Join(s,f_2(\Sigma))$。其中$f_2$是summary index的一部分，将数据中的节点映射到摘要中的节点。最后，给定h中任意两点，其最短路径可有Lemmas 5,6,7和最短路径算法在$Join(s,f_2(\Sigma))$中找到最短路的一个下限。实际应用中，我们从summary和三角不等式中找一个更高的下限。 6.2 The algorithm Data structures. $q={w_1,…w_m}$: query G={V,E}: a (condensed) RDF graph $W_i$: vertices in V containing the keyword $w_i$ ${a_1,…a_m}$: m empty priority queues, one for each query keyword. M: 集合中每个元素对应目前探索到的独一无二的node，记录他们能够到达那个关键词以及历经的分区。M中每个条目是四元组$(u,S,d_l,d_u)$。u是后向搜索中包含关键$w_i$的第一个节点。S存储搜索过程中路径的一系列partitions及其portal（exit node），因此S是(portal, partition root)的集合。The algorithm. In the first iteration. 对于每个来自$W_i$的点u，我们从summary index对u所述的分区根节点v检索。并将检索结果插入M和$a_i$中。 In the j-th iteration. 从所有的$a_i$中pop出最小的条，即$(v,(u,S,d_l,d_u))$(line 10). v是当前分区的根节点。S中最后的对是$(l,v_l)$：路径在$v_l$点离开根为$v_l$的分区并进入现分区。$\mathcal{L}={\mathcal{l}^{‘}_1,\mathcal{l}^{‘}_2,…}$表示根节点为v的分区的portals。对于每个$l^{‘}$按照6.1节的方法计算$d(l,l^{‘})$或$d(u,l^{‘})$的上下限。然后第14行更新，其中$v_r$是与$l^{‘}$相连的下一个分区的根节点。M只有在两种情况下停止更新：(i)S的路径产生了环。(ii)$d_l+d^{‘}_l$比当前第i个列表中第k大的上限还要大。 如果M[v]的所有条目非空，则以v为根节点的分区是候选答案。将m个关键词对应的列表组合起来就是联通子图。 然后我们拿到所选分区的实际数据（如何拿到在第7节），进行二级搜索。 Termination condition. Lemma 8,9. Lemma 8 Denote an entry in the priority queue as $(v,(u,S,d_l,d_u))$, then for any $v^{‘}$ in the partition rooted at v and the length of any path starting from u and using the portals in S is $d(u,v^{‘}\le d_l$.Lemm 9 Denote the top entry in the priority queue $a_i$ as $(v,(u,S,d_l,d_u))$, then for any explored path p from $w_i$ in the queue $a_i$, the length of p, written as d(p), has $d(p)\le d_l$.Lemma 10 let $g_1$ be a possible unexplored candidate answer rooted at a vertex in a partition h, with $h\in P_t$, s(g_1)>\sum^m_{i=1}{d}^i_l\tag{3}Lemma 11 Denote the bset possible unexplored candidate answer as $g_2$, which is rooted at a vertex in the partition h where $h\in P-P_t$, then s(g_2)>\sum^m_{i=1}f(t_i)\hat{d}^i_l+(1-f(t_i))d^i_l, \tag{4}where $f(t_i)=1\, if \, t_i\neq nil\, otherwise \, f(t_i)=0.$ The termination condition. 在未探索分区最有可能的答案是$s(g_1)$，如(3)式。在所有探索分区的最有可能的答案是$s(g_2)$，如(4)式。将得分升序排名第k的答案表示为g，则算法停止条件是$s(g)\le min (s(g_1),s(g_2))$. Theorem 2 Summ finds the top-k answers A(q,k) for any top-k keyword search query q on an RDF graph. 7 Accessing data and update在对摘要图搜索完成后，我们需要从实体数据中检索出所选择分区，一个常用的方法是将三元组按分区存储并编上分区的id，但这样更新比较麻烦，并需要独立的存储。我们将RDF数据存储在RDF中，并通过构建的SPARQL查询动态的检索出该分区的数据。 Theorem 3 Homomorphism Throrem [1]. Let $q$ and $q^{‘}$ be relational queries over the same data D. Then $q^{‘}(D)\subseteq q(D)$ iff there exists a homomorphism mapping $f: q\rightarrow q^{‘}$. 因为$c\rightarrow h_t \rightarrow h$因此用c作为SPARQL查询的pattern并结合Theorem 3可以抽取h。两个关键问题： 从$h_t$的集合到c通常有多对一的映射，使得若用c为query pattern会导致a low selectivity. 为解决此问题，我们在query pattern中从目标分区到相应变量间绑定了常量。 在构建S的过程中，并不保存每个c，而是当c是s的子树时将c插入到$s\in S$中。为了从s中构建SPARQL，首先找到根节点，然后拓展到叶子。 8 ExperimentsDatasets]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>RDF</tag>
        <tag>2017年8月</tag>
        <tag>Keyword</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《RDF Keyword-based Query Technology Meets a Real-World Dataset》——论文笔记]]></title>
    <url>%2F2017%2F08%2F15%2Ftest%2F</url>
    <content type="text"><![CDATA[nucleus ABSTRACT本文介绍了一个工业项目，其通过将RDF技术和关键词搜索结合，开发出一种便于利用碳氢化合物对大型数据库进行数据访问的工具。该工具的特色是通过RDF schema和RDF数据，无需用户介入将关键词转化为SPARQL查询。工具还提供了一系列接口，如specify keywords, as well as filters and unit measures, and presents the results with the help of a table and a graph方便用户使用。 1. INTRODUCTION首先分析现有的网络上的关键词搜索技术，总结其成功的原因： 简单易用的用户接口 有效的文档检索机制 符合用户期望的排序算法 对比来看，数据库管理系统提供了复杂的查询语言，一些数据库应用虽然创建了用户接口，让用户填一些空进行查询，隐藏查询语言的复杂性，但并不友好。我们提供关键词搜索接口，通过把关键词转换为查询语言，将用户从精准填空中解放出来。 关于关系型数据库的关键词查询出现了一段时间，现在也出现了关于RDF数据上的关键词查询。RDF不区分数据和元数据，因此关键词可能和类的名字、属性的描述或者数据的值匹配。RDF管理系统有时和提供推理层会以surpass/relational 视图对RDF数据产生推导数据，因此关键词也可能匹配推导数据。 本文贡献： 定义RDF数据上关键词查询的答案。 通过利用RDF的schema和RDF数据集将关键词查询转换为SPARQL查询。 通过自动补全功能和filter、 unit measures的帮助允许用户精确关键字。 进行实验验证了工具的性能。 2. Related WorkKeyword-based query processing. 分为以下几类： schema-based：使用conceptual schema编译查询。 graph-based：直接在图上操作。 parttern-based：从RDF数据中挖掘pattern替代conceptual schema。 fully automatic：在关键词查询时无需依靠用户干预。 BANKS and BLINKS是早期的graph-based工具。schema-based工具基于candidate networks （CNs）探索外键将关键词转化为SQL。例子有：DISCOVER，DBXplorer。 SPARK是早期的pattern-based RDF graph-based tool。[21]提出想法：利用类的层级从原始图中生成summary graphs，[26]负责实现。[24]挖掘tree pattern。[27]提出挖掘等价的structure patterns to summarize 知识图。[7]基于张量计算对RDF关键词查询。 QUICK[25]是一个RDF schema-based tool，需要用户介入。 本文的工具是schema-based并且fully automatic。从早期的graph-based工具中借鉴了生成由RDF schema引发的图的斯坦纳树来减少equijoins的想法。我们引入了新概念nucleus，其包含一个类，一个属性列表，一个属性值列表。nucleus 一定程度上和tuple相似。然后Steiner tree把那些包含关键词的nucleus连接起来。 和QUICK比较相似，但我们的RDF数据有rich schema并且低歧义，所以我们是全自动的转换。 Triplification of the relational database. 因为关系数据库经常是normalized不可直接映射到RDF，我们首先创造了定义了unnormalized关系视图，然后利用R2RML映射。设计良好RDF schema帮助了关键词到SPARQL的转化，首先，RDF数据集具有已知模式的假设不应被视为缺点。实际上，大部分的LOD数据集确实有一个已知的模式（词汇或本体）[17]。此外，在像我们这样的企业环境中，RDF数据集通常是关系数据库的三元组化。第二，即使不能改变（关系或RDF）模式，也可以添加一个在视图的帮助下定义的概念层，这些概念层隐藏规范化，在关系情况下，或设计不当的RDF模式，这两种情况都会导致处理基于关键字的查询时的歧义。 Benchmarks. 他人所用的数据集及查询。 3. BASIC DEFINITIONS3.1 RDF EssentialsIRI(Internationalized Resource Identifier)：表示一个资源。literal：一个基础值，如字符串，数字等blank node：local identifier，可以被新的IRI替代。 本文中IRI代表所有的IRI的集合，L代表所有的literal的集合。 (s,p,o): s-IRI/ a blank node. p-IRI, o-IRI,a blank node or a literal. RDF 三元组和RDF图等价。 RDF Schema 不提供实际的应用程序专用的类和属性，而是提供了描述应用程序专用的类和属性的框架。RDF Schema 中的类与面向对象编程语言中的类非常相似。这就使得资源能够作为类的实例和类的子类来被定义。介绍了RDF Schema 及其一系列属性 An RDF schema is a set S of RDF triples that use the RDF-S vocabulary to declare classes, properties, property domains and ranges, and sub-class and sub-property axioms. A simple RDF schema is a RDF schema that contains only class declarations, object and datatype property declarations and subclass axioms (and no sub-property axioms). 我们引入一个labelled graph, $D_s$ 被称为RDF schema diagram： the nodes of DS are the classes declared in S; there is an edge from class c to class d labelled with subClassOf iff c is declared as a subclass of d in S, and there is an edge from class c to class d labelled with p iff p is declared in S as an object property with domain c and range d. RDF 数据集T follows RDF schema S的条件： $S\subseteq T$ T中的所有类和属性在S中都被定义 T中的三元组除了那些在S中的都满足S中声明的限制。 3.2 Keyword-Based QueriesT: an RDF dataset.$G_T$: $G_T$ is the corresponding RDF graph.S: an RDF schema.K: A keyword-based query—- a set of literals.match $\mathbf L \times \mathbf L \rightarrow [0,1]$:literal之间的相似函数。$\sigma \in (0,1]$: similarity threshold.MM[K,S]:metadata matches between K and metadata descriptions of the classes and properties in S. MM[K,T]=\{ (k,(r,p,v)) \in K\times T/ (r,p,v)\in S \wedge match(k,v)\le \sigma\}VM[K,T]: property value matches between K and property values of T. VM[K,T]=\{ (k,(r,p,v)) \in K\times T/ (r,p,v)\notin S \wedge match(k,v)\le \sigma\}$M[K,T]=MM[K,T]\cup VM[K,T]$: matches between K and T. 答案的顺序：Given a directed graph G, let |G| denote the number of nodes and edges of G and #c(G) denote the number of connected components of G, when the direction of the edges of G is disregarded. We define a partial order “&lt;” for graphs such that, given two graphs G and G’, G]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>keyword</tag>
        <tag>RDF</tag>
        <tag>SPARQL</tag>
        <tag>2017年8月</tag>
      </tags>
  </entry>
</search>
