title: 数据集熟悉
author: 刘凯鑫
date: 2017-11-28 20:42:25
tags:
---
目前dbpedia和YAGO提供的可视化工具其实都比较弱，需要一个一个的手动添加点，进行可视化。不过他们都是基于wiki百科，如果要想例子，估计只能拍脑门想概念了，所以就先这个工作先放一放吧，读一读师兄说的构建索引的文章看看。

在阅读《Fast Hierarchy Construction for Dense Subgraphs》时，看到了数据集稠密这样的字眼。想到还是应该对数据集整体有个把握，调查到两个可视化工具[VOSViewer](http://www.vosviewer.com/download#Instructions)和NWB Tool，还有相应的[调研论文](http://gb.oversea.cnki.net/kcms/detail/detail.aspx?filename=QBKX201502020&DBName=cjfqtotal&dbcode=cjfq)，[知乎](https://www.zhihu.com/question/51061274)再次对Dbpedia进行调研~

[DBpedia-2016-10](http://downloads.dbpedia.org/2016-10/)：


Statistics

The English version of the DBpedia knowledge base currently describes **6.6M entities** of which 4.9M have abstracts, 1.9M have geo coordinates and 1.7M depictions. In total, **5.5M** resources are classified in a consistent ontology, consisting of 1.5M persons, 840K places (including 513K populated places), 496K works (including 139K music albums, 111K films and 21K video games), 286K organizations (including 70K companies and 55K educational institutions), 306K species, 58K plants and 6K diseases. The total number of resources in English DBpedia is **18M** that, besides the 6.6M resources, includes 1.7M skos concepts (categories), 7.7M redirect pages, 269K disambiguation pages and 1.7M intermediate nodes.

Altogether the DBpedia 2016-10 release consists of 13 billion (2016-04: 11.5 billion) pieces of information (RDF triples) out of which 1.7 billion (2016-04: 1.6 billion) were extracted from the English edition of Wikipedia, 6.6 billion (2016-04: 6 billion) were extracted from other language editions and 4.8 billion (2016-04: 4 billion) from Wikipedia Commons and Wikidata.

In addition, adding the large NIF datasets for each language edition (see details below) increased the number of triples further by over 9 billion, bringing the overall count up to 23 billion triples.